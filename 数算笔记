## 笔试复习

1）数据项是数据的最小单位，数据元素是数据的基本单位
例如，“学生”这个数据元素可能包含“姓名”、“学号”、“年龄”等数据项。

2）顺序表是连续储存的，于是可以很快访问第 i 个节点（支持随机访问）
- 顺序表修改查询快，链表插入删除快
1. **存储结构（物理结构）**：指数据在计算机中的实际存储方式，如顺序存储（数组）、链式存储（链表）等。
    
    - **链表**是一种典型的链式存储结构，通过指针或引用将节点连接起来。
        
2. **逻辑结构**：描述数据的逻辑关系，与具体存储无关。其他选项均属于逻辑结构：
    
    - **A. 线性表**：逻辑结构，可用顺序存储（数组）或链式存储（链表）实现。
        
    - **C. 栈** 和 **D. 队列**：是特殊的线性表（逻辑结构），可通过数组或链表实现。
- **逻辑结构**：描述数据之间的关系（线性、树、图等）。
    
- **存储结构**：描述数据在内存中的存储方式（顺序、链式、索引、散列）。
    
- **链表** 是存储结构，而 **栈、队列、线性表** 是逻辑结构。

3）循环队列

| 条件                      | 含义     |
| ------------------------- | -------- |
| rear == front           | 队列为空 |
| (rear + 1) % n == front | 队列为满 |

4）一个树转为二叉树
### 树转换为二叉树的规则

1. **左孩子-右兄弟表示法（Child-Sibling Representation）**：
    
    - 每个结点的**第一个子结点**作为其**左孩子**。
        
    - 该结点的**兄弟结点**（同一层的其他子结点）作为其**右孩子**。
        
2. **转换过程**：
    
    - 从树的**根结点**开始，将其第一个子结点作为左孩子。
        
    - 该子结点的兄弟结点依次作为右孩子（形成右链）。
        
    - 递归处理所有子树

5）卡特兰数
$$
C_{n}=\frac{1}{n+1}\binom{2n}{n}
$$
- n 个节点能构造多少种二叉树
- n 个元素的栈有多少出栈序列

6）对于完全二叉树，叶子节点数= $\left\lceil  \frac{n}{2}  \right\rceil$

| 类型       | 公式                                                |
| -------- | ------------------------------------------------- |
| 完全二叉树叶子数 | $\left\lceil \dfrac{n}{2} \right\rceil$           |
| 度为0结点数   | $n_0 = \left\lceil \dfrac{n + 1}{2} \right\rceil$ |
| 度为1结点数   | $n_1 = 0 \text{ 或 } 1$（取决于是否为满二叉树）                |
| 度为2结点数   | $n_2 = n_0 - 1$                                   |

7）
【数据结构】设 F 是一个森林，B 是由 F 变换得的二叉树。若 F 中有 n 个非终端结点，则 B 中右指针域为空的结点有多少个

https://blog.csdn.net/lauie545/article/details/120107604

在森林的每一颗子树中，转化二叉树后右指针域为空代表着这个节点是兄弟组的最后一个，再往右没有兄弟了。所以有多少个兄弟组就有多少右指针域为空。每个兄弟组都有自己的父亲，父亲就是非终端结点（分支结点）。

所以每棵子树转化后右指针域为空的结点树等于非终端结点（分支结点）。

又因为所有根结点转化后，最右边的根结点右指针域也为空。

所以最终转化后右指针域为空的结点总数为：
非终端结点数+1。

8）平衡二叉树
记得复习维护平衡


9）B 树又叫平衡多路查找树。
一棵m阶的B 树 (m叉树)的特性如下：
1. 根节点至少有两个孩子。
2. 每个非根节点至少有M/2（上取整）个孩子，至多有M个孩子。
3. 每个叶子节点至少有 M/2-1（上取整）个关键字，至多有 M-1 个关键字。并以升序排列。（注：叶子节点是没有孩子）
4. key[i] 和 key[i+1] 之间的孩子节点的值介于 key[i] 和 key[i+1] 之间。
5. 所有的叶子节点都在同一层。

10）快速排序
1. 挖坑法（一开始的坑位为基准值）
2. 霍尔法（碰撞后将碰撞位置与 pivot 交换）

11）堆排序
从下往上非叶节点下沉调整

12）m 叉树性质
1. 总结点数：$N=N_{0}+N_{1}+\cdots+N_{m}$
2. 边数与节点数关系：边数 $=N-1$
3. 一条边贡献两个度数
13）二叉搜索树的删除
替换原则：当前节点左子树最大节点/右子树最小节点

14）**常见排序算法的稳定性总结**

| 排序算法     | 是否稳定  | 原因              |
| -------- | ----- | --------------- |
| **冒泡排序** | ✅ 稳定  | 相邻比较，相等不交换      |
| **插入排序** | ✅ 稳定  | 逐个插入，相等不交换      |
| **归并排序** | ✅ 稳定  | 合并时保持相等元素的顺序    |
| **选择排序** | ❌ 不稳定 | 交换可能破坏相等元素的顺序   |
| **快速排序** | ❌ 不稳定 | 分区过程可能改变相等元素的顺序 |
| **希尔排序** | ❌ 不稳定 | 分组跳跃交换可能导致顺序改变  |
| **堆排序**  | ❌ 不稳定 | 堆调整可能改变相等元素的顺序  |

15）建堆的最小时间复杂度是 $O(n)$
- 从非叶节点开始建堆

从上到下建堆的时候，求最小儿子的比较也算一次比较

16）双散列法解决冲突
第一个函数用来找位置，第二个用来生成探测序列

### 位运算

### 堆的使用


### 集合论到位运算
> 在代码中，集合和二进制数、位运算有着很多联系
#### 前言
我们可以将集合用二进制表示
包含非负整数的集合 $S$ 可以用如下方式“压缩”成一个数字：$f(S)=\sum_{i\in S}2^{i}$
例如：$\left\{ 0,2,3 \right\}\implies1101_{(2)}$

利用位运算「并行计算」的特点，我们可以高效地做一些和集合有关的运算。按照常见的应用场景，可以分为以下四类：

#### 一、集合与集合
| 术语    | 集合           | 位运算       | 集合示例                                 | 位运算示例              |
| ----- | ------------ | --------- | ------------------------------------ | ------------------ |
| 交集    | 𝐴 ∩ 𝐵      | a & b     | {0, 2, 3} ∩ {0, 1, 2} = {0, 2}       | 1101 & 0111 = 0101 |
| 并集    | 𝐴 ∪ 𝐵      | a ∣ b     | {0, 2, 3} ∪ {0, 1, 2} = {0, 1, 2, 3} | 1101 ∣ 0111 = 1111 |
| 对称差   | 𝐴 Δ 𝐵      | a ⊕ b     | {0, 2, 3} Δ {0, 1, 2} = {1, 3}       | 1101 ⊕ 0111 = 1010 |
| 差     | 𝐴 ∖ 𝐵      | a & ∼b    | {0, 2, 3} ∖ {1, 2} = {0, 3}          | 1101 & 1001 = 1001 |
| 差（子集） | 𝐴 ∖ 𝐵, B⊆A | a ⊕ b     | {0, 2, 3} ∖ {0, 2} = {3}             | 1101 ⊕ 0101 = 1000 |
| 包含于   | 𝐴 ⊆ 𝐵      | a & b = a | {0, 2} ⊆ {0, 2, 3}                   | 0101 & 1101 = 0101 |
|       |              | a ∣ b = b |                                      | 0101 ∣ 1101 = 1101 |

#### 二、集合与元素

| 术语           | 集合                                  | 位运算                        |
| ------------ | ----------------------------------- | -------------------------- |
| 空集           | $\phi$                              | 0                          |
| 单元素集合        | $\{𝑖\}$                            | $1 << 𝑖$                  |
| 全集           | $𝑈 = \{0, 1, 2, …, 𝑛 − 1\}$       | $(1 << 𝑛) − 1$            |
| 补集           | $\complement_{U} S = U \setminus S$ | $((1 << 𝑛) − 1) \oplus s$ |
| 属于           | $𝑖 \in 𝑆$                         | $(s >> 𝑖) \& 1 = 1$       |
| 不属于          | $𝑖 \notin 𝑆$                      | $(s >> 𝑖) \& 1 = 0$       |
| 添加元素         | $S \cup \{𝑖\}$                     | $s \mid (1 << 𝑖)$         |
| 删除元素         | $S \setminus \{𝑖\}$                | $s \& \sim (1 << 𝑖)$      |
| 删除元素（一定在集合中） | $S \setminus \{𝑖\}, 𝑖 \in S$      | $s \oplus (1 << 𝑖)$       |
| 删除最小元素       |                                     | $s \& (s - 1)$             |
#### 三、遍历集合
```python
for i in range(n): 
	if (s >> i) & 1: 
```

#### 四、枚举集合

枚举所有集合
```python
for i in range(1<<n):
```

枚举给定集合的非空子集
```python
sub = s 
while sub: # 处理 sub 的逻辑 
	sub = (sub - 1) & s
```

# A 线性结构
## 1 链表
### 1. 单向链表
结构：每个节点包含 `val`（数据）和 `next` （指向下一个节点的指针）
```python
class ListNode:
    def __init__(self, val=0, next=None):
        self.val = val
        self.next = next
```

特点：只能单向遍历

相关算法：
遍历
```python
cur=head
while cur:
	########
	cur=cur.next
```
插入、删除这些基本操作
```python
#以删除为例
dummy=ListNode()
dummy.next=head
cur=dummy
while cur.next:
	if cur.next.val==val:
		cur.next=cur.next.next
	else:
		cur=cur.next
```
- 这里用到了哨兵节点 `dummy` 为的是统一删除的操作，而避免对边界的处理（一般需要对链表进行修改的，用哨兵节点都可以简化问题）
- 与此同时，while 的判断也不一样，这是因为要对节点本身进行操作，此时用 `while cur.next:`，如果是遍历节点用 `while cur:`

反转链表
```python
pre=None
cur=head
while cur is not None:
	pre,pre.next,cur=cur,pre,cur.next
```

合并链表

快慢指针（寻找中间节点、检测环形链表）

### 2. 双向链表
结构：增加了 `prev` 指向前驱节点
```python
class ListNode:
    def __init__(self, val=0, prev=None, next=None):
        self.val = val
        self.prev = prev
        self.next = next
```

### 3. 哨兵节点
在头节点前面加入一个不含数据的哨兵节点 `dummy node`
好处：能够统一删除/插入的逻辑，而不用考虑边界情况

| **场景**                  | **作用**                               | **经典问题**                          |
|---------------------------|---------------------------------------|---------------------------------------|
| 头节点可能被修改/删除      | 避免空指针或额外判断                   | 删除节点、反转链表、合并链表           |
| 需要返回新链表的头节点     | 保留对真实头节点的引用                 | 分隔链表、重排链表                    |
| 操作涉及前驱节点           | 提供统一的前驱起点（如 `dummy.next`） | 删除倒数第 N 个节点、反转链表区间        |

**核心思想**：通过添加冗余节点，将特殊 case 转化为一般 case，减少边界判断。

## 2 栈的使用

### Ⅰ中序表达式转换 （调度场算法）
假设中缀表达式是由空格分隔的标记字符串。操作符标记包括\*, /, + 和 -，以及左右括号 ( 和 )。操作数标记是单字符标识符 A, B, C 等等。遵循以下步骤可以产生按后缀顺序排列的标记字符串：

1. 创建一个名为 `opstack` 的空栈用于存放操作符，并创建一个空列表用于输出。
2. 使用字符串方法 `split` 将输入的中缀字符串转换成列表。
3. 从左到右扫描标记列表：
   - 如果标记是操作数，则将其附加到输出列表的末尾。
   - 如果标记是左括号，则将其压入 `opstack` 栈中。
   - 如果标记是右括号，则从 `opstack` 中弹出元素直到移除相应的左括号为止，并将每个操作符附加到输出列表的末尾。
   - 如果标记是操作符 \*, /, + 或 -，则将其压入 `opstack` 栈中。但是，首先移除已在 `opstack` 上且具有更高或相同优先级的所有操作符，并将它们附加到输出列表的末尾。
4. 当输入表达式被完全处理后，检查 `opstack`。栈上任何剩余的操作符都可以被移除并附加到输出列表的末尾。

 <mark>关于栈使用的重要原则</mark>

【李冠黎 24 工学院】

1. **栈的基本用途是用于“等待”**。具体来说，当遇到一条指令，而这条指令的操作依赖于后续的指令时，可以选择将这条指令先入栈，“稍作等待”，直到遍历到后面部分了解到具体如何操作后再利用 `pop` 方法回过头来处理该指令。这是栈使用的总体原则。

2. **栈与括号匹配的关系密切**。很多涉及栈的问题都涉及到括号匹配问题，其核心在于识别一对括号内所包含的内容。这时同样可以应用第一条原则。当我们遇到左括号时，由于不清楚它对应的右括号在哪里，所以先将其入栈。等到遇到右括号时，再回头找到匹配的左括号，并进行相应的处理。

3. **理解栈相关问题时，研究给定示例非常重要**。在解决栈相关的问题之前，先大致研究一下给出的示例，分析答案和输入数据（或称“密文”）之间的关系非常有帮助。例如，在中序表达式转后序表达式的题目中，通过观察转换后的结果可以发现数字的顺序保持不变，而对于每一个运算单元，符号总是位于最后。这表明：数字不需要入栈，因为它们的操作不依赖于后续的指令，可以直接添加到结果中。相反，运算符需要入栈，因为我们尚未确定该运算符所属的运算单元将在何处结束。一旦根据某些条件判断出运算单元结束，就可以有序地将运算符从栈中弹出，并加入到结果中。
- 中序表达式→后序表达式→解析树
- 建立解析树的过程实际上就是求值的过程
### Ⅱ 栈模拟 DFS

#### 1. 通用栈模拟 DFS 框架
以下是适用于多种遍历顺序的通用代码框架：

```python
def dfs_with_stack(root):
    stack = [(root, False)]  # (node, visited)
    while stack:
        node, visited = stack.pop()
        if visited:
            # 后序处理
            process_node_post(node)
        else:
            # 前序处理
            process_node_pre(node)
            
            # 压栈顺序决定遍历顺序
            # 前序/中序/后序通过调整压栈顺序实现
            for child in reversed(get_children(node)):
                stack.append((child, False))
            stack.append((node, True))  # 标记为已访问，待后序处理
```

#### 2. 不同遍历顺序的实现

##### (1) 前序遍历（Pre-order）
处理顺序：根 → 左 → 右  
压栈顺序：右 → 左 → 根（标记）

```python
def preorder(root):
    stack = [(root, False)]
    while stack:
        node, visited = stack.pop()
        if not visited:
            print(node.val)  # 前序处理
            for child in reversed(node.children):
                stack.append((child, False))
```

##### (2) 中序遍历（In-order，二叉树特有）
处理顺序：左 → 根 → 右  
压栈顺序：右 → 根（标记）→ 左

```python
def inorder(root):
    stack = [(root, False)]
    while stack:
        node, visited = stack.pop()
        if not visited:
            if node.right:
                stack.append((node.right, False))
            stack.append((node, True))  # 标记
            if node.left:
                stack.append((node.left, False))
        else:
            print(node.val)  # 中序处理
```

##### (3) 后序遍历（Post-order）
处理顺序：左 → 右 → 根  
压栈顺序：根（标记）→ 右 → 左

```python
def postorder(root):
    stack = [(root, False)]
    while stack:
        node, visited = stack.pop()
        if not visited:
            stack.append((node, True))  # 标记
            for child in reversed(node.children):
                stack.append((child, False))
        else:
            print(node.val)  # 后序处理
```

#### 3. 复杂应用示例

##### (1) 计算子树大小
```python
def subtree_sizes(root):
    stack = [(root, False)]
    size = [0] * (n + 1)
    while stack:
        node, visited = stack.pop()
        if not visited:
            stack.append((node, True))
            for child in reversed(node.children):
                stack.append((child, False))
        else:
            size[node] = 1 + sum(size[child] for child in node.children)
    return size
```

##### (2) 记录根到叶子的路径
```python
def all_paths(root):
    stack = [(root, False, [])]
    paths = []
    while stack:
        node, visited, path = stack.pop()
        if not visited:
            new_path = path + [node.val]
            if not node.children:  # 叶子节点
                paths.append(new_path)
            stack.append((node, True, new_path))
            for child in reversed(node.children):
                stack.append((child, False, new_path))
    return paths
```

#### 4. 性能优化技巧

1. **双栈法**：对于后序遍历，可以使用两个栈来避免标记
   ```python
   def postorder_two_stacks(root):
       stack1 = [root]
       stack2 = []
       while stack1:
           node = stack1.pop()
           stack2.append(node)
           for child in node.children:
               stack1.append(child)
       while stack2:
           print(stack2.pop().val)
   ```

2. **Morris 遍历**：对于二叉树，可以做到 O (1) 空间复杂度

#### 5. 常见问题解决

| 问题类型               | 栈模拟方案                          |
|-----------------------|-----------------------------------|
| 判断树对称             | 同时进行左右子树的镜像 DFS            |
| 最近公共祖先（LCA）    | 后序遍历时记录祖先信息               |
| 树的最大深度           | 记录当前深度和最大深度               |
| 路径总和               | 携带当前路径和的目标值               |

#### 6. 复杂度分析

- 时间复杂度：O (N) 每个节点处理一次
- 空间复杂度：O (H) 栈的最大深度为树高
  - 最坏情况（链状树）：O (N)
  - 最好情况（平衡树）：O (logN)

## 3 其他
### 1. KMP 算法
问题：给定模式串，在字符串中寻找是否存在模式串
思想：通过建立 `next` 数组回滚模式串，使得不用回溯字符串指针

```python
# 生成 next 数组
# next[j] 表示下标 j 之前的模式串 p 中，最长相等前后缀的长度
def generateNext(p: str):
    m = len(p)
    next = [0 for _ in range(m)]  # 初始化数组元素全部为 0
    
    left = 0         # left 表示前缀串开始所在的下标位置
    for right in range(1, m):  # right 表示后缀串开始所在的下标位置
        while left > 0 and p[left] != p[right]: 
        # 匹配不成功, left 进行回退, left == 0 时停止回退
            left = next[left - 1]    # left 进行回退操作
        if p[left] == p[right]:         
        # 匹配成功，找到相同的前后缀，先让 left += 1，此时 left 为前缀长度
            left += 1
        next[right] = left              
        # 记录前缀长度，更新 next[right], 结束本次循环, right += 1

    return next

# KMP 匹配算法，T 为文本串，p 为模式串
def kmp(T: str, p: str) -> int:
    n, m = len(T), len(p)
    
    next = generateNext(p)   # 生成 next 数组
    
    j = 0                    # j 为模式串中当前匹配的位置
    for i in range(n):       # i 为文本串中当前匹配的位置
        while j > 0 and T[i] != p[j]:           
        # 如果模式串前缀匹配不成功, 将模式串进行回退, j == 0 时停止回退
            j = next[j - 1]
        if T[i] == p[j]:  
        # 当前模式串前缀匹配成功，令 j += 1，继续匹配
            j += 1
        if j == m:                              
        # 当前模式串完全匹配成功，返回匹配开始位置
            return i - j + 1
    return -1       # 匹配失败，返回 -1
            

```

### 2. 排序算法
Python 内置了非常强大的排序功能，并且对于元组的排序是根据顺序进行的，所以当我们想要进行多数据的排序时
```python
arr.sort(key=lambda x:(x[0],x[1],x[2]))
```
# B 树状结构
## 1 树的表示方法
用类表示
```python
class Treenode:
	def __init__(self,val):
		self.val=val
		self.left=None
		self.right=None
		###self.childrem=[](对于多叉树)
```
用邻接表表示
一个节点对应一个 `key`，然后他的 `value` 对应他的孩子
- 建树有时要善于利用栈的结构（思考什么时候入栈什么时候弹出）
## 2 常用操作
对于树，最重要的是**复制**，对于一棵树的操作可以同样用在子树上，所以**递归**是最常用的写法
> 关于树的遍历（求一些树内元素的性质），一般都需要遍历树，这时候就往四种遍历结构上思考，怎么遍历，在遍历的时候怎么操作：
> 1. 回溯什么样的值？
> 2. 是否有全局变量可以不用参与回溯
> **树在 dfs 的时候有递和归两个过程，前中后序的区别便是在归上做文章**
### Ⅰ 遍历（Traversal）
前序遍历（Pre-order Traversal）
- 根→左→右
```python
def preorder_traversal(root):
    if root:
        print(root.val)  # 访问根节点
        preorder_traversal(root.left)  # 递归遍历左子树
        preorder_traversal(root.right)  # 递归遍历右子树
```

中序遍历（In-order Traversal）
- 左→根→右
```python
def inorder_traversal(root):
    if root:
        inorder_traversal(root.left)  # 递归遍历左子树
        print(root.val)  # 访问根节点
        inorder_traversal(root.right)  # 递归遍历右子树
```

后序遍历（Post-order Traversal）
- 左→右→根
```python
def postorder_traversal(root):
    if root:
        postorder_traversal(root.left)  # 递归遍历左子树
        postorder_traversal(root.right)  # 递归遍历右子树
        print(root.val)  # 访问根节点
```

注：
- 中序+前序/后序能唯一确定二叉树，中序标明了左右子树位置，前/后序标明了根节点位置

层序遍历：BFS
```python
def level_order_traversal(root):
    if root is None:
        return []
    result = []
    queue = deque([root])
    while queue:
        node = queue.popleft()
        result.append(node.data)
        if node.left:
            queue.append(node.left)
        if node.right:
            queue.append(node.right)
    return result
```

### Ⅱ 求树的高度（深度）

```python
def tree_height(root):
    if not root:
        return 0
    else:
        left_height = tree_height(root.left)
        right_height = tree_height(root.right)
        return max(left_height, right_height) + 1
```

### Ⅲ 翻转二叉树

```python
def invert_tree(root):
    if root:
        root.left, root.right = invert_tree(root.right), invert_tree(root.left)
    return root
```

## 3 各种树的应用

完全二叉树：
指的是除最后一层外，其他层完全被占据，最后一层的节点都在左侧
表示：
通常采用数组储存，不用占用额外的指针空间
- 父节点 `i//2`
- 左孩子 `2*i`
- 右孩子 `2*i+1`
下面的三个例子都是完全二叉树的应用


### Ⅰ 哈夫曼编码
哈夫曼编码是根据字符使用频率（freq）建立的一种最优的二叉编码树
基本思路是
1. 为每个字符创造一个节点，包括值和频率，并且按频率排序加入堆中
2. 弹出两个频率最小的节点，合并后值为 `None`, 频率 `freq=freq1+freq2`，`left=Node1`，`right=Node2` 再加入堆中
3. 如此重复，直到堆中只剩一个节点的时候，就搭建完哈夫曼树
```python
import heapq
class Node():
    def __init__(self,val,freq):
        self.val = val
        self.freq = freq
        self.left = None
        self.right = None
    def __lt__(self, other):
        if self.freq==other.freq:
            return self.val<other.val
        return self.freq < other.freq

n=int(input())
heap=[]
for i in range(n):
    char,freq=input().split()
    freq=int(freq)
    heap.append(Node(char,freq))
heapq.heapify(heap)
while len(heap)>1:
    left=heapq.heappop(heap)
    right=heapq.heappop(heap)
    node=Node(min(left.val,right.val),left.freq+right.freq)
    node.left=left
    node.right=right
    heapq.heappush(heap,node)
tree=heapq.heappop(heap)
```

### Ⅱ 最小堆建立
我们可以设计一个堆结构，使得父节点小于子节点。支持插入 `insert` 和删除并返回最小值 `delMin` 的操作
思路：
1. 堆需满足父节点小于子节点，这需要我们在插入和删除的同时进行维护（我们创造一个 `Heap` 类，用列表来维护堆）
2. `insert`：我们可以先插入到列表末端，然后不断与父节点比较，使得数据上浮 `up`
3. `delMin`：可以先取出列表头部输出，并令头部为末尾的数，再弹出，最后让这个头部的数下沉 `down`，动态维护堆的有序

```python
class Heap:
    def __init__(self):
        self.arr = [0]  # 堆的存储数组，索引从1开始
        self.size = 0    # 堆的大小

    def up(self, i):
        # 上浮操作，维护堆的性质
        while i // 2 > 0:
            if self.arr[i] < self.arr[i // 2]:  # 如果当前节点比父节点小
                self.arr[i], self.arr[i // 2] = self.arr[i // 2], self.arr[i]  # 交换
            i = i // 2  # 继续向上检查

    def insert(self, i):
        # 插入元素
        self.arr.append(i)
        self.size += 1
        self.up(self.size)  # 上浮新插入的元素

    def down(self, i):
        # 下沉操作，维护堆的性质
        while i * 2 <= self.size:
            mc = self.minChild(i)  # 找到较小的子节点
            if self.arr[i] > self.arr[mc]:  # 如果当前节点比子节点大
                self.arr[i], self.arr[mc] = self.arr[mc], self.arr[i]  # 交换
            i = mc  # 继续向下检查

    def minChild(self, i):
        # 返回较小的子节点的索引
        if i * 2 + 1 > self.size:  # 如果右子节点不存在
            return i * 2
        if self.arr[i * 2] < self.arr[i * 2 + 1]:  # 左子节点更小
            return i * 2
        else:  # 右子节点更小
            return i * 2 + 1

    def delMin(self):
        # 删除并返回堆顶元素（最小值）
        res = self.arr[1]  # 堆顶元素
        self.arr[1] = self.arr[self.size]  # 将最后一个元素移到堆顶
        self.arr.pop()  # 删除最后一个元素
        self.size -= 1
        self.down(1)  # 下沉新的堆顶元素
        return res

h = Heap()
n = int(input())
for _ in range(n):
    inp = list(map(int, input().split()))
    if inp[0] == 1:
        h.insert(inp[1])  
    else:
        print(h.delMin())
```

### Ⅲ 二叉搜索树
二叉搜索树（Binary Search Tree，BST），它是映射的另一种实现。我们感兴趣的不是元素在树中的确切位置，而是<mark>如何利用二叉树结构提供高效的搜索。</mark>

二叉搜索树依赖于这样一个性质：<mark>小于父节点的键都在左子树中，大于父节点的键则都在右子树中。我们称这个性质为二叉搜索性。</mark>
- 这样意味着一个二叉搜索树的中序表达式就是顺序排列

思路：利用递归
```python
def insert(root, val):
    if not root:
        return TreeNode(val)
    if val < root.val:
        root.left = insert(root.left, val)
    elif val > root.val:
        root.right = insert(root.right, val)
    return root
```
### Ⅳ 前缀树

思路：
1. 创造一个节点类：1. 字典保存下一个字符 2. 判断是否为结尾
2. 字典可以用列表替代（空间会少一点？）
3. 注意：前缀树的前提是**按照字符长度排序**

```python
class TrieNode:
    def __init__(self):
        self.children = {}  # 字典保存子节点
        self.is_end_of_word = False  # 标记是否是单词结尾

class Trie:
    def __init__(self):
        self.root = TrieNode()  # 根节点

    def insert(self, word: str) -> None:
        current = self.root
        for char in word:
            if char not in current.children:
                current.children[char] = TrieNode()
            current = current.children[char]
        current.is_end_of_word = True  # 标记单词结束

    def search(self, word: str) -> bool:
        current = self.root
        for char in word:
            if char not in current.children:
                return False
            current = current.children[char]
        return current.is_end_of_word  # 必须精确匹配单词结尾

    def startsWith(self, prefix: str) -> bool:
        current = self.root
        for char in prefix:
            if char not in current.children:
                return False
            current = current.children[char]
        return True  # 只要前缀存在即可


```

### Ⅴ 并查集
并查集是用于高效管理集合的合并与查询
1. **`find(x)`**：查找元素 `x` 所属的集合（通常返回根节点）。
    
2. **`union(x, y)`**：合并 `x` 和 `y` 所在的集合。
    
3. **路径压缩** 和 **按秩合并** 优化，使操作接近 O(1)。

为了高效地实现并查集操作，通常会使用<mark>树形结构</mark>来表示集合之间的关系。<mark>每个集合可以用一个树表示，其中树的根节点是集合的代表元素</mark>（即管理、搜索和合并父节点）

简化版本（去掉按秩合并）：
```python
    def __init__(self, n):
        self.parent = list(range(n))  # 初始化每个元素的父节点是自己

    def find(self, x):
        if self.parent[x] != x:
            self.parent[x] = self.find(self.parent[x])  # 路径压缩
        return self.parent[x]

    def union(self, x, y):
        x_root = self.find(x)
        y_root = self.find(y)
        if x_root != y_root:
            self.parent[y_root] = x_root  
```

加上按秩合并：
```python
class DisjointSet:
    def __init__(self, n):
        self.parent = list(range(n))  # 初始化每个元素的父节点是自己
        self.rank = [0] * n          # 按秩合并优化

    def find(self, x):
        if self.parent[x] != x:  # 路径压缩
            self.parent[x] = self.find(self.parent[x])
        return self.parent[x]

    def union(self, x, y):
        x_root = self.find(x)
        y_root = self.find(y)
        if x_root == y_root:  # 已经在同一集合
            return
        # 按秩合并（小树合并到大树）
        if self.rank[x_root] < self.rank[y_root]:
            self.parent[x_root] = y_root
        else:
            self.parent[y_root] = x_root
            if self.rank[x_root] == self.rank[y_root]:
                self.rank[x_root] += 1

```


### Ⅵ 树状数组/二叉索引树（Fenwick Tree）

二叉索引树（Binary Indexed Tree），又称 Fenwick Tree，是一种高效的数据结构，主要用于**动态维护前缀和**以及**高效计算区间和**。

1）核心功能：
- **单点更新**：在 O (log n) 时间内修改某个元素的值  
- **区间查询**：在 O (log n) 时间内查询前 i 个元素的和  

2）实现原理

使用数组 `tree` 维护信息：
- `tree[i]` 管理原数组 `[i-lowbit(i)+1, i]` 区间的和  
- `lowbit(i)` 表示 i 的二进制中最低位的 1 所代表的值 
- `tree[i]` 的父节点是 `tree[i+lowbit(i)]`


Lowbit 函数实现
```python
def lowbit(x):
    return x & -x
```

更新操作
```python
def update(index, delta):
    while index <= size:
        tree[index] += delta
        index += lowbit(index)
```

查询操作
```python
def query(index):
    res = 0
    while index > 0:
        res += tree[index]
        index -= lowbit(index)
    return res
```

# C 图算法
## 1 图的储存方式

图的结构比较复杂，我们需要表示顶点和边。一个图可能有任意多个（有限个）顶点，而且任何两个顶点之间都可能存在边。我们在实现图的存储时，重点需要关注边与顶点之间的关联关系，这是图的存储的关键。

图的存储可以通过「顺序存储结构」和「链式存储结构」来实现。其中顺序存储结构包括邻接矩阵。链式存储结构包括邻接表、链式前向星、十字链表和邻接多重表。

接下来我们来介绍几个常用的图的存储结构。在下文中，我们约定用 nn 代表顶点数目，mm 代表边数目，TD(vi)TD(vi​) 表示顶点 vivi​ 的度。

### 1.1 邻接矩阵

#### 1.1.1 邻接矩阵的原理描述
> **邻接矩阵（Adjacency Matrix）**：使用一个二维数组 `adj` 来存储顶点之间的邻接关系。
> 
> - 对于无权图来说，如果 `adj[i][j]` 为 `1`，则说明顶点 `v_i` 到 `v_j` 存在边；如果 `adj[i][j]` 为 `0`，则说明顶点 `v_i` 到 `v_j` 不存在边。
> - 对于带权图来说，如果 `adj[i][j]` 为 `w`，并且 `w ≠ ∞`（即 `w != float('inf')`），则说明顶点 `v_i` 到 `v_j` 的权值为 `w`；如果 `adj[i][j]` 为 `∞`（即 `float('inf')`），则说明顶点 `v_i` 到 `v_j` 不存在边。

在下面的示意图中，左侧是一个无向图，右侧则是该无向图对应的邻接矩阵结构。

![](https://qcdn.itcharge.cn/images/20220317144826.png)

邻接矩阵的特点：

- 优点：实现简单，并且可以直接查询顶点 `v_i` 与 `v_j` 之间是否有边存在，还可以直接查询边的权值。
- 缺点：初始化效率和遍历效率较低，空间开销大，空间利用率低，并且不能存储重复边，也不便于增删节点。

#### 1.1.2 邻接矩阵的算法分析

- **时间复杂度**：
    - **初始化操作**：O(n²)。
    - **查询、添加或删除边操作**：O(1)。
    - **获取某个点的所有边操作**：O(n)。
    - **图的遍历操作** ：O(n²)。
- **空间复杂度**：O(n²)。
    

#### 1.1.3 邻接矩阵的代码实现

```python
class Graph:
    def __init__(self, n):
        self.n = n  # 顶点数
        self.adj = [[None]*n for _ in range(n)]  # 邻接矩阵
    
    def add_edge(self, u, v, w):
        """添加边 u->v，权值w"""
        self.adj[u][v] = w
    
    def get_edge(self, u, v):
        """获取边权，不存在返回None"""
        return self.adj[u][v]
```
### 1.3 邻接表

#### 1.3.1 邻接表的原理描述

> **邻接表（Adjacency List）**：使用顺序存储和链式存储相结合的存储结构来存储图的顶点和边。其数据结构包括两个部分，其中一个部分是数组，主要用来存放顶点的数据信息，另一个部分是链表，用来存放边信息。

在邻接表的存储方法中，对于对图中每个顶点 `v_i` 建立一个线性链表，把所有邻接于`v_i` ​的顶点链接到单链表上。这样对于具有 `n` 个顶点的图而言，其邻接表结构由 `n` 个线性链表组成。

在下面的示意图中，左侧是一个有向图，右侧则是该有向图对应的邻接表结构。

![](https://qcdn.itcharge.cn/images/20220317154531.png)

#### 1.3.2 邻接表的算法分析

邻接表的时间复杂度：

- 图的初始化和创建操作：O(n+m)。
- 查询是否存在 vivi​ 到 vjvj​ 的边：O(TD(vi))。
- 遍历某个点的所有边：O(TD(vi))。
- 遍历整张图：O(n+m)。

邻接表的空间复杂度：

- 空间复杂度：O(n+m)。

#### 1.3.3 邻接表的代码实现

**无权图**
```python
from collections import defaultdict
class Graph:
    def __init__(self):
        self.adj = defaultdict(set)  
        # 格式：{ 起点: { 终点1, 终点2 } }
    def add_edge(self, u, v):
        self.adj[u].add(v)
```

**带权图**
```python
from collections import defaultdict
class Graph:
    def __init__(self):
        self.adj = defaultdict(dict)
        # 格式：{ 起点: { 终点: 权值 } }
    def add_edge(self, u, v, weight=None):
        self.adj[u][v] = weight 
    	#self.adj[v][u] = weight  双向添加
```

## 2 图的遍历问题
> **图的遍历**：与树的遍历类似，图的遍历指的是从图的某一个顶点出发，按照某种搜索方式对图中的所有节点都仅访问一次。

图的遍历是求解图的连通性问题、拓扑排序和求关键路径等算法的基础。

根据搜索方式的不同，可将图的遍历分为「**深度优先搜索**」和「**广度优先搜索**」。

### 拓扑排序

#### Ⅰ概念
有向图的边提供了点与点的偏序关系，由集合上这种偏序关系得到集合的一个全序，这种操作称之为**拓扑排序**

#### Ⅱ前提 
图为有向无环图，有环 (loop) 就没办法排序

#### Ⅲ算法（BFS）(Kahn)
思路：在普通 BFS 的基础上维护节点的入度，每次选择入度为 0 的点（没有其他点在其之前）进入队列

1. 统计图中每个点的入度，储存进数组 indegree
2. 选取入度为 0 的节点加入队列
3. 从队列中弹出一个节点
	1. 将该节点加入 res
	2. 把该节点指向的所有节点入度减 1
4. 重复步骤 3，直到 len (q)=0
5. 比较 res 和节点数，判断是否存在 loop

时间复杂度：O (n+e)

```python
from collections import deque  

def topoSortBfs(self):
    inDeg = {node: 0 for node in self.graph}
    for node in self.graph:
        for adj in self.graph[node]:
            inDeg[adj] += 1

    q = deque([node for node, d in inDeg.items() if d == 0])
    res = []
    while q:
        u = q.popleft()
        res.append(u)
        for v in self.graph[u]:
            inDeg[v] -= 1
            if inDeg[v] == 0:
                q.append(v)
    
    # 检查结果长度是否包含所有节点，若否则存在环
    if len(res) != len(self.graph):
        return None
    return res
```

## 3 图的连通性问题

### 强连通分量 (SCC)
#### Ⅰ概念 
如果一个有向图中，存在一条回路，所有的结点至少被经过一次，这样的图为**强连通图**。在强连通图的基础上加入一些点和路径，使得当前的图不在强连通，称原来的强连通的部分为**强连通分量**。

#### Ⅱ算法：tarjan

```python
def tarjan(graph):
    def dfs(node):
        nonlocal index, stack, indices, low_link, on_stack, sccs
        index += 1
        indices[node] = index
        low_link[node] = index
        stack.append(node)
        on_stack[node] = True
        
        for neighbor in graph[node]:
            if indices[neighbor] == 0:  # Neighbor not visited yet
                dfs(neighbor)
                low_link[node] = min(low_link[node], low_link[neighbor])
            elif on_stack[neighbor]:  # Neighbor is in the current SCC
                low_link[node] = min(low_link[node], indices[neighbor])
        
        if indices[node] == low_link[node]:
            scc = []
            while True:
                top = stack.pop()
                on_stack[top] = False
                scc.append(top)
                if top == node:
                    break
            sccs.append(scc)
    
    index = 0
    stack = []
    indices = [0] * len(graph)
    low_link = [0] * len(graph)
    on_stack = [False] * len(graph)
    sccs = []
    
    for node in range(len(graph)):
        if indices[node] == 0:
            dfs(node)
    
    return sccs

# Example
graph = [[1],        # Node 0 points to Node 1
         [2, 4],     # Node 1 points to Node 2 and Node 4
         [3, 5],     # Node 2 points to Node 3 and Node 5
         [0, 6],     # Node 3 points to Node 0 and Node 6
         [5],        # Node 4 points to Node 5
         [4],        # Node 5 points to Node 4
         [7],        # Node 6 points to Node 7
         [5, 6]]     # Node 7 points to Node 5 and Node 6

sccs = tarjan(graph)
print("Strongly Connected Components:")
for scc in sccs:
    print(scc)

"""
Strongly Connected Components:
[4, 5]
[7, 6]
[3, 2, 1, 0]
"""
```
代码结构与变量说明
- **`graph`** : 输入的邻接表表示的有向图。
- **`index`** : 全局计数器，记录节点被访问的顺序（时间戳）。
- **`stack`** : 保存当前 DFS 路径中的节点，用于回溯形成 SCC。
- **`indices`** : 记录每个节点被访问时的索引（时间戳），初始化为 0 表示未访问。
- **`low_link`** : 记录节点能回溯到的最早的节点索引，初始化为 0。
- **`on_stack`** : 标记节点是否在栈中，避免重复处理。
- **`sccs`** : 存储所有找到的强连通分量。

核心函数：DFS 遍历

1. **初始化节点** ：
    
    - 当首次访问节点时，分配 `index` 和 `low_link` 值，节点入栈并标记 `on_stack` 为True。
2. **遍历邻居节点** ：
    
    - **未访问的邻居** ：递归调用 DFS，递归返回后更新当前节点的 `low_link` 为当前值和邻居 `low_link` 的较小值。
    - **已访问且在栈中的邻居** ：说明存在回边，直接更新当前节点的 `low_link` 为当前值和邻居 `indices` 的较小值。
3. **识别 SCC 根节点** ：
    
    - 当节点的 `indices` 等于 `low_link` 时，该节点是 SCC 的根节点。此时弹出栈中所有后续节点直至当前节点，形成一个 SCC，并将其添加到结果列表。

算法执行流程

1. **遍历所有节点** ：确保每个未访问的节点都进行 DFS。
2. **SCC 的形成** ：通过栈的后进先出特性，确保每个 SCC 的节点按正确顺序弹出。


## 4 图的生成树问题
> **图的生成树（Spanning Tree）**：如果连通图 G 的一个子图是一棵包含图 G 所有顶点的树，则称该子图为 G 的生成树。生成树是连通图的包含图中的所有顶点的极小连通子图。图的生成树不惟一。从不同的顶点出发进行遍历，可以得到不同的生成树。


### **1）Kruskal**

目的：用最小的边权重链接所有的点（无向图）
思路：
1. 按照边的权重排序（从小到大）
2. 接下来开始链接点（如何表示链接？用并查集）
	1. 先判断是否链接
	2. 如果没有链接把他们连起来

```python
class DisjointSet:
    def __init__(self, num_vertices):
        self.parent = list(range(num_vertices))
        self.rank = [0] * num_vertices

    def find(self, x):
        if self.parent[x] != x:
            self.parent[x] = self.find(self.parent[x])
        return self.parent[x]

    def union(self, x, y):
        root_x = self.find(x)
        root_y = self.find(y)

        if root_x != root_y:
            if self.rank[root_x] < self.rank[root_y]:
                self.parent[root_x] = root_y
            elif self.rank[root_x] > self.rank[root_y]:
                self.parent[root_y] = root_x
            else:
                self.parent[root_x] = root_y
                self.rank[root_y] += 1


def kruskal(graph):
    num_vertices = len(graph)
    edges = []

    # 构建边集
    for i in range(num_vertices):
        for j in range(i + 1, num_vertices):
            if graph[i][j] != 0:
                edges.append((i, j, graph[i][j]))

    # 按照权重排序
    edges.sort(key=lambda x: x[2])

    # 初始化并查集
    disjoint_set = DisjointSet(num_vertices)

    # 构建最小生成树的边集
    minimum_spanning_tree = []

    for edge in edges:
        u, v, weight = edge
        if disjoint_set.find(u) != disjoint_set.find(v):
            disjoint_set.union(u, v)
            minimum_spanning_tree.append((u, v, weight))

    return minimum_spanning_tree
```

在上述代码中，`graph` 是一个二维矩阵，表示带权无向图的邻接矩阵。`graph[i][j]` 表示顶点 i 和顶点 j 之间的边的权重。

Kruskal 算法的时间复杂度为 O (ElogE)，其中 E 是边的数量。排序边集的时间复杂度为 O (ElogE)，并查集操作的时间复杂度为 O (Eα(V))，其中 α 是 Ackermann 函数的反函数，近似为常数。因此，总体上来说，Kruskal 算法的时间复杂度可以近似为 O (ElogE)。

### **2）Prim**
**Prim 算法的基本思想**
1. **初始化**：任选一个顶点作为起点，加入生成树。
2. **扩展生成树**：每次选择 **当前生成树到未加入顶点的最短边**，并将该边的另一个顶点加入生成树。
3. **重复**：直到所有顶点都加入生成树。

- Prim 适合稠密图（边多），Kruskal 适合稀疏图
```python
import heapq  
  
while True:  
    try:  
        n=int(input())  
        mat=[]  
        for i in range(n):  
            mat.append(list(map(int,input().split())))  
        res=0  
        h=[(0,0)]  
        heapq.heapify(h)  
        visit={0}  
        while h and len(visit)<n:  
            dist,cur=heapq.heappop(h)  
            if cur in visit:  
                continue  
            res+=dist  
            visit.add(cur)  
            for i,road in enumerate(mat[cur]):  
                if i==cur or i in visit:  
                    continue  
                heapq.heappush(h,(road,i))  
        print(res)  
    except EOFError:  
        break
```

## 5 图的最短路径问题
### [[计算概论/笔记#11 dijkstra 算法（dp+greedy+BFS）|Dijkstra]] （无负权图）
### Bellman-Ford（可以处理负权图）
- **思想**：==动态规划 + 松弛思想==
- 每次迭代尝试通过已知的最短路径更新其他路径（松弛）
- 最多只需进行 V-1 次迭代，因为最短路径最多经过 V-1 个顶点
- 第 V 次检测是否还能更新，用于发现负权环

> ✅ 关键：松弛操作（Relaxation）

> **Bellman-Ford算法**：Bellman-Ford算法用于解决单源最短路径问题，与Dijkstra算法不同，它可以处理带有负权边的图。算法的基本思想是通过松弛操作逐步更新节点的最短路径估计值，直到收敛到最终结果。具体步骤如下：
> 
> - 初始化一个距离数组，用于记录源节点到所有其他节点的最短距离。初始时，源节点的距离为0，其他节点的距离为无穷大。
> - 进行V-1次循环（V是图中的节点数），每次循环对所有边进行松弛操作。如果从节点u到节点v的路径经过节点u的距离加上边(u, v)的权重比当前已知的从源节点到节点v的最短路径更短，则更新最短路径。
> - 检查是否存在负权回路。==如果在V-1次循环后，仍然可以通过松弛操作更新最短路径，则说明存在负权回路，因此无法确定最短路径==。

Bellman-Ford算法的时间复杂度为，其中V是图中的节点数，E是图中的边数，适合==边稀疏图==（边数远小于 ）。

###### ✅ Bellman-Ford 为什么“松弛 V-1 次”是对的？

最短路径最多 V-1 条边；每次松弛尝试传递更短的路径。

📌 **本质是“路径最多有 V-1 条边”**

- 在没有负环的图中，从起点出发到任意一个点，最多走 **V-1 条边**（因为图中有 V 个点，路径不能重复经过点，否则就成环了）。
- 每次“松弛”一条边，相当于尝试把路径从 u → v 变短（如果可以）。
- 所以我们执行 V-1 轮，每轮遍历所有边，把所有可能的路径更新出来。

> 🌱 **直觉类比**：  
> 假设你传递消息，起点知道自己是 0 步，第一轮传给邻居，第二轮邻居的邻居知道……传 V-1 轮就把消息传满了。  
> 这就像广播传播，最远需要 V-1 步。

---

✅ **正确性的归纳证明（略简化）：**

- **初始状态**：起点到自己距离是 0，其他是 ∞。
- **归纳假设**：第 k 轮后，所有最短路径至多包含 k 条边的点都被正确更新。
- **第 k+1 轮**：再通过所有边松弛，更新包含 k+1 条边的路径。
- 所以 V-1 次可以更新最多包含 V-1 条边的最短路径。
- 第 V 次如果还能更新，那一定存在环（负权环）。

> 
> SPFA算法的基本思想如下：
> 
> 1. 初始化源节点的最短距离为0，其他节点的最短距离为正无穷大。
> 2. 将源节点加入队列中，并标记为已访问。
> 3. 循环执行以下步骤直到队列为空：
>     - 从队列中取出一个节点作为当前节点。
>     - 遍历当前节点的所有邻接节点：
>         - 如果经过当前节点到达该邻接节点的路径比当前记录的最短路径更短，则更新最短路径，并将该邻接节点加入队列中。
> 4. 当队列为空时，算法结束，所有节点的最短路径已计算出来。
> 
> SPFA算法在实际应用中通常表现出良好的性能，尤其适用于稀疏图（边数相对较少）和存在负权边的情况。然而，需要注意的是，==如果图中存在负权环路，SPFA算法将无法给出正确的结果==。

##### ✅示例Bellman-Ford 算法

```python
def bellman_ford(graph, V, source):
    # 初始化距离
    dist = [float('inf')] * V
    dist[source] = 0

    # 松弛 V-1 次
    for _ in range(V - 1):
        for u, v, w in graph:
            if dist[u] != float('inf') and dist[u] + w < dist[v]:
                dist[v] = dist[u] + w

    # 检测负权环
    for u, v, w in graph:
        if dist[u] != float('inf') and dist[u] + w < dist[v]:
            print("图中存在负权环")
            return None

    return dist

# 图是边列表，每条边是 (起点, 终点, 权重)
edges = [
    (0, 1, 5),
    (0, 2, 4),
    (1, 3, 3),
    (2, 1, 6),
    (3, 2, -2)
]
V = 4
source = 0

print(bellman_ford(edges, V, source))
```

##### ✅Dijkstra算法和Bellman-Ford算法对比

Dijkstra算法和Bellman-Ford算法都可以用于计算从一个源点到图中其他所有顶点的最短路径，但它们在处理问题的方式、适用场景以及算法效率上有所区别。

- **Dijkstra算法**：主要用于没有负权边的加权图。它能够有效地找到从单个源点到图中所有其他顶点的最短路径。该算法采用贪心策略，每次选择当前距离最小的未访问节点进行扩展。由于其高效的实现（比如使用优先队列），对于大规模稀疏图来说，Dijkstra算法的时间复杂度通常为O((V+E) log V)，其中V是顶点数，E是边数。
    
- **Bellman-Ford算法**：适用于可能包含负权边的加权图，并且可以检测出负权环（即总权重为负的环）。如果存在负权环并且它是可达的，那么最短路径不再有意义，因为可以通过绕环多次任意减少路径长度。Bellman-Ford算法通过迭代每条边最多V-1次来松弛（更新）到达每个顶点的最短路径估计值，因此其时间复杂度为O(VE)。此外，Bellman-Ford还可以报告是否发现可以从源节点到达的负权环。
    

简而言之，虽然两个算法都可用于寻找从一个源点到图中其他所有顶点的最短路径，但在面对可能存在负权边的情况时，Bellman-Ford算法更为适用；而在仅处理非负权边的情况下，Dijkstra算法因其更高的效率通常是首选。

### Floyd 算法（多源最短路径）
> ✅ 关键：中间点枚举（引入“桥梁”路径）
- 状态定义：`dist[i][j]` 表示 i 到 j 的最短路径长度
- 转移方程：
    `dist[i][j]=min⁡(dist[i][j], dist[i][k]+dist[k][j])`
    表示是否通过中间点 k 能让路径更短



具体步骤如下：

1. 初始化一个二维数组`dist`，用于存储任意两个顶点之间的最短距离。初始时，`dist[i][j]`表示顶点i到顶点j的直接边的权重，如果i和j不直接相连，则权重为无穷大。
    
2. 对于每个顶点k，在更新`dist`数组时，考虑顶点k作为中间节点的情况。遍历所有的顶点对(i, j)，如果通过顶点k可以使得从顶点i到顶点j的路径变短，则更新`dist[i][j]`为更小的值。
    
    `dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])`
    
3. 重复进行上述步骤，对于每个顶点作为中间节点，进行迭代更新`dist`数组。最终，`dist`数组中存储的就是所有顶点之间的最短路径。

以下是一个使用Floyd-Warshall算法求解所有顶点之间最短路径的示例代码：

```python
def floyd_warshall(graph):
    n = len(graph)
    dist = [[float('inf')] * n for _ in range(n)]

    for i in range(n):
        for j in range(n):
            if i == j:
                dist[i][j] = 0
            elif j in graph[i]:
                dist[i][j] = graph[i][j]

    for k in range(n):
        for i in range(n):
            for j in range(n):
                dist[i][j] = min(dist[i][j], dist[i][k] + dist[k][j])

    return dist
```

在上述代码中，`graph`是一个字典，用于表示图的邻接关系。它的键表示起始顶点，值表示一个字典，其中键表示终点顶点，值表示对应边的权重。

你可以将你的图表示为一个邻接矩阵或邻接表，并将其作为参数传递给`floyd_warshall`函数。函数将返回一个二维数组，其中`dist[i][j]`表示从顶点i到顶点j的最短路径长度。

## 6 图的关键路径问题




### 图的邻接表
#### Ⅰ 二维矩阵表示
```python
n, m = map(int, input().split())
adjacency_matrix = [[0]*n for _ in range(n)]
for _ in range(m):
    u, v = map(int, input().split())
    adjacency_matrix[u][v] = 1
    adjacency_matrix[v][u] = 1 #无向图才要这一行
```

#### Ⅱ定义类表示
思路：用一个字典储存图，key 为点，value 记录所连边
```python
from collections import defaultdict
 
class Graph:
    def __init__(self, isDirected=False):
        # 以邻接表的方式表示一张图
        self.graph = defaultdict(list)
        self.isDirected = isDirected
 
    def addEdge(self, start, end):
        # 将end添加到start节点的邻接表
        self.graph[start].append(end)
 
        if self.isDirected is False:
            # 如果是无向图，则双向追加。
            self.graph[end].append(start)
        else:
            self.graph[end] = self.graph[end]
```







```

Terminal 命令
上传文件夹
```ssh
scp -r "path" rocky@10.129.242.36:/home/user/backup
```

测试代码
```ssh
bash ../../offlinejudge.zsh e1.py ./
```

卡特兰树
